import pandas as pd
import os

STAGING_FILE = "data/staging/weather_clean.json"
REFINED_FILE = "data/refined/weather.parquet"

os.makedirs("data/refined", exist_ok=True)

# --- Chargement du STAGING ---
print("üì• Chargement du fichier STAGING...")
df = pd.read_json(STAGING_FILE, lines=True)

# --- V√©rification des colonnes attendues ---
expected_cols = {
    "date", "city", "temperature_c",
    "humidity", "wind_kmh", "precip_mm", "is_storm"
}

missing = expected_cols - set(df.columns)
if missing:
    raise ValueError(f"‚ùå Colonnes manquantes dans STAGING : {missing}")

# --- Typage final (important pour DuckDB et la qualit√© du Parquet) ---
df["date"] = pd.to_datetime(df["date"])
df["city"] = df["city"].astype("category")

numeric_cols = ["temperature_c", "humidity", "wind_kmh", "precip_mm", "is_storm"]
for col in numeric_cols:
    df[col] = pd.to_numeric(df[col], errors="coerce")

# --- Tri temporel ---
df = df.sort_values("date")

# --- Export Parquet optimis√© ---
df.to_parquet(
    REFINED_FILE,
    index=False,
    compression="snappy"  
)

print("üì¶ Donn√©es converties ‚Üí PARQUET (REFINED)")
print(f"‚Üí {REFINED_FILE}")
print("‚úî Compression : snappy")
print("‚úî Lignes :", len(df))
print(df.head())
