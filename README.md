
# ðŸŒ¦ï¸ Pipeline MÃ©tÃ©o â€“ Landing â†’ Staging â†’ Refined
Pipeline locale inspirÃ©e des zones AWS S3 / Glue / Athena.

## ðŸ§­ Objectif
Mini-pipeline Data structurÃ©e :
- Landing (CSV)
- Staging (JSON nettoyÃ©)
- Refined (Parquet)
- Analyse complÃ¨te en notebook

## ðŸš€ Installation

### 1) CrÃ©er un environnement virtuel
```bash
python -m venv .venv
source .venv/Scripts/activate
```

### 2) Installer les dÃ©pendances
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

## ðŸ—ï¸ Pipeline â€“ Ã‰tapes

### 1ï¸âƒ£ GÃ©nÃ©ration des donnÃ©es mÃ©tÃ©o
```bash
python scripts/generate_weather_data.py
```

### 2ï¸âƒ£ Nettoyage (Staging)
```bash
python scripts/clean_weather_data.py
```

### 3ï¸âƒ£ Conversion en Parquet (Refined)
```bash
python scripts/to_parquet.py
```

### 4ï¸âƒ£ Analyse
```bash
jupyter notebook analysis/meteo_analysis.ipynb
```

## ðŸ“‚ Structure du projet

```
pipeline_meteo/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ staging/
â”‚   â””â”€â”€ refined/
â”œâ”€â”€ analysis/
â”‚   â””â”€â”€ meteo_analysis.ipynb
â”œâ”€â”€ scripts/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ðŸ“Š Pipeline (Mermaid)

```mermaid
graph LR
    A[CSV - Landing] --> B[JSON - Staging]
    B --> C[Parquet - Refined]
    C --> D[Notebook Analyse]
```

Projet prÃªt Ã  Ãªtre Ã©tendu vers AWS S3 / Glue / Athena.
